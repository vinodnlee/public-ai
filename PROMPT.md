# ğŸ§  Project Prompt â€” DeepAgent SQL Chat Application

> Use this prompt with any AI coding assistant (GitHub Copilot, ChatGPT, Claude, Cursor)
> to regenerate, extend, or explain the full application.

---

## ğŸ¯ Goal

Build a **Chat Application** using **DeepAgent** that allows users to ask natural language questions,
which are translated into SQL queries, executed against a **PostgreSQL database** using a
**CodeAct Agent Tool**, and the results are streamed back to the UI in real-time.

---

## ğŸ—ï¸ Architecture

Design a **4-layer architecture** with the following layers:

### New Layers Added

#### Semantic Layer (`api/src/semantic/`)
Bridges the gap between raw SQL schema and LLM understanding by adding business meaning to tables and columns.

- `SemanticColumn` â€” display name, plain-English description, example values, sensitivity flag
- `SemanticTable` â€” display name, purpose description, common query examples, join hints
- `SemanticRegistry` â€” central store of all SemanticTable definitions; pre-seeded with 8 tables: `departments`, `employees`, `employee_info`, `suppliers`, `products`, `customers`, `orders`, `order_items`
- `SemanticLayer` â€” merges physical schema from any `DatabaseAdapter` with registry definitions to produce a single LLM-ready context string. Falls back to raw schema for tables with no semantic entry.

#### Database Adapter Interface (`api/src/db/adapters/`)
Abstracts all database operations behind a single `DatabaseAdapter` ABC so the rest of the application has zero database-specific code.

- `DatabaseAdapter` (abstract) â€” `connect()`, `disconnect()`, `ping()`, `execute_query()`, `get_tables()`, `get_columns()`, `get_foreign_keys()`, `dialect`
- `PostgreSQLAdapter` â€” full production implementation via SQLAlchemy + asyncpg
- `MySQLAdapter` â€” implementation via SQLAlchemy + aiomysql
- `SQLiteAdapter` â€” implementation via SQLAlchemy + aiosqlite  
- `AdapterFactory` â€” reads `DB_TYPE` env var and returns the correct singleton adapter

---

### Layer 1 â€” UI Layer

- **React** frontend with `EventSource` for SSE streaming
- Chat interface that renders:
  - `thinking` events as subtle animated status hints
  - `sql` events as syntax-highlighted code blocks
  - `executing` events as loading indicators
  - `result` events as paginated data tables
  - `token` events as flowing streamed text
  - `done` event to finalize and stop the blinking cursor
- **FastAPI** backend as API Gateway with:
  - `POST /api/chat` â€” accepts the user query, returns a `stream_url`
  - `GET /api/chat/stream/{stream_id}` â€” SSE endpoint returning `text/event-stream`
  - `EventSourceResponse` from `sse-starlette`
  - Auth middleware placeholder
- **Redis** for session management (conversation history per `session_id`)

### Layer 2 â€” DeepAgent Layer

- **DeepAgent Orchestrator** â€” built on **`deepagents.create_deep_agent`** (supervisor + subagent graph)
  - Supervisor delegates NL queries to a `sql-executor` subagent via LangGraph routing
  - `init_chat_model(model="openai:gpt-4o")` as the backbone LLM
  - `execute_sql` registered as a LangChain `@tool` (plain async function) in the sql-executor subagent
  - `graph.astream_events(version="v2")` for fine-grained event streaming:
    - `on_chat_model_stream` â†’ `EventType.TOKEN`
    - `on_tool_start` â†’ `EventType.TOOL_CALL` + `EventType.SQL` + `EventType.THINKING`
    - `on_tool_end` â†’ re-emits captured `RESULT` / `ERROR` events from CodeActSQLTool
- **LLM Backend** (`langchain-openai` / `init_chat_model`) for:
  - Natural language understanding
  - SQL intent parsing via OpenAI tool-calling
  - Result summarization
  - Context-aware multi-turn conversation
- **Agent Memory** â€” `InMemorySaver` (LangGraph checkpointer) keyed by `thread_id`; last 10 turns persisted to Redis per `session_id`
- **Tool Registry** â€” LangChain `@tool`-decorated async functions passed to subagent definition

### Layer 3 â€” CodeAct Tool Layer

- **CodeAct Agent Tool** â€” generates and executes Python/SQL code dynamically
  - SQL code generation from natural language
  - Code execution engine
  - Error handling and retry
  - Result validation
- **SQL Query Builder**
  - NL â†’ SQL translation
  - Query optimization hints
  - Parameterized queries
  - SQL injection prevention (SELECT-only enforcement)
- **Schema Inspector** â€” introspects PostgreSQL for context-aware generation
  - Table discovery
  - Column types
  - Foreign key relationships
  - Schema caching
- **DB Connection Pool** using `SQLAlchemy (asyncio)` + `asyncpg`
  - Connection pooling
  - Async execution
  - Transaction management
  - Timeout handling

### Layer 4 â€” Database Layer

- **PostgreSQL Primary** â€” read/write, business data tables, port 5432
  - `departments` â€” company departments with budget
  - `employees` â€” full employee roster (self-referencing manager FK, employment type, status)
  - `employee_info` â€” sensitive HR data (DOB, address, emergency contact, bank last 4)
  - `suppliers` â€” product vendors / supplier contacts
  - `products` â€” product catalogue with SKU, pricing, stock, reorder levels
  - `customers` â€” registered customers with loyalty tier (standard/silver/gold/platinum)
  - `orders` â€” purchase orders with full status lifecycle
  - `order_items` â€” line items with computed `line_total` generated column
- **PostgreSQL Read Replica** â€” read-only query execution, analytics
- **Redis Cache** â€” caches query results by SHA-256 hash of SQL, with TTL

#### Database Bootstrap Scripts (`db/postgress/`)

| File | Purpose |
|---|---|
| `00_run_all.sql` | Master script â€” runs all files in order + prints row counts |
| `01_schema.sql` | All `CREATE TABLE`, indexes, FK constraints, `updated_at` triggers |
| `02_insert_departments.sql` | 10 departments |
| `03_insert_employees.sql` | 42 employees (C-suite â†’ intern, active/on-leave/terminated) |
| `04_insert_employee_info.sql` | Extended HR data for all 42 employees |
| `05_insert_suppliers.sql` | 8 suppliers (US, UK, Germany, China, Mexico) |
| `06_insert_products.sql` | 28 products across Electronics, Office, Software, Furniture, Accessories |
| `07_insert_customers.sql` | 30 customers across all loyalty tiers |
| `08_insert_orders.sql` | 30 orders covering all status states |
| `09_insert_order_items.sql` | ~65 order line items |

```bash
# Bootstrap the database
psql -U postgres -c "CREATE DATABASE chatdb;"
psql -U postgres -d chatdb -f db/postgress/00_run_all.sql
```

---

## ğŸ”„ End-to-End Request Flow (13 Steps)

```
1.  User types a natural language query in the Chat UI
2.  React sends POST /api/chat with { query, session_id }
3.  API Gateway stores query and returns { stream_url }
4.  React opens new EventSource(stream_url)
5.  DeepAgent is invoked with query + PostgreSQL schema context
6.  DeepAgent sends query + schema to LLM â†’ LLM reasons and plans
7.  LLM selects CodeAct SQL Tool from Tool Registry
8.  CodeAct inspects DB schema via Schema Inspector
9.  CodeAct generates a safe parameterized SQL SELECT query
10. SQL is executed via DB Connection Pool on PostgreSQL Read Replica
11. Raw results (columns + rows) returned to CodeAct Tool
12. CodeAct returns structured result to DeepAgent
13. DeepAgent/LLM formats natural language response
    â†’ SSE stream â†’ React EventSource updates UI in real-time
```

---

## ğŸ“¡ SSE Event Types (DeepAgent â†’ React)

```json
{ "type": "thinking",  "content": "Analyzing your question..." }
{ "type": "thinking",  "content": "Generating SQL query..." }
{ "type": "tool_call", "tool": "codeact_sql", "input": "top 10 customers by revenue" }
{ "type": "sql",       "content": "SELECT id, name, revenue FROM customers ORDER BY revenue DESC LIMIT 10" }
{ "type": "executing", "content": "Running query on PostgreSQL..." }
{ "type": "result",    "columns": ["id","name","revenue"], "rows": [...], "row_count": 10 }
{ "type": "token",     "content": "The top customer is Acme Corp with..." }
{ "type": "done" }
```

---

## ğŸ› ï¸ Tech Stack

| Layer            | Technology                                                     |
|------------------|----------------------------------------------------------------|
| Frontend         | React 18, TypeScript, Vite, Tailwind CSS                       |
| SSE Client       | Native `EventSource` API                                       |
| API Gateway      | FastAPI, `sse-starlette`                                       |
| Session Store    | Redis (`redis-py` asyncio)                                     |
| Agent Framework  | `deepagents>=0.3.8` â€” `create_deep_agent` (supervisor + subagent graph) |
| Agent Streaming  | `graph.astream_events(version="v2")` via LangGraph              |
| LLM Backend      | `init_chat_model("openai:gpt-4o")` via `langchain-openai`       |
| Agent Tool       | LangChain `@tool` async function â†’ CodeAct SQL Tool             |
| LangChain Pkgs   | `deepagents>=0.3.8`, `langchain>=0.2`, `langgraph>=0.2`         |
| ORM / DB Driver  | SQLAlchemy (asyncio), asyncpg / aiomysql / aiosqlite           |
| Database         | PostgreSQL 15 (Primary + Read Replica)                         |
| Result Cache     | Redis                                                          |
| Containerization | Docker, Docker Compose, Nginx 1.27-alpine                      |

---

## ğŸ“ Required Directory Structure

```
1.SQL-Query-execution-tool/
â”œâ”€â”€ README.md
â”œâ”€â”€ PROMPT.md
â”œâ”€â”€ DeepAgent-SQL-Chat-Architecture.drawio
â”‚
â”œâ”€â”€ deploy/                              â† all Docker / container files
â”‚   â”œâ”€â”€ docker-compose.yml               â† run `docker compose up --build` from here
â”‚   â”œâ”€â”€ .env.docker                      â† env template for Docker (copy to .env)
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ Dockerfile                   â† 2-stage Python 3.12-slim build
â”‚   â”‚   â””â”€â”€ Dockerfile.dockerignore      â† per-service build context filter
â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â”œâ”€â”€ Dockerfile                   â† 2-stage Node 20 â†’ Nginx 1.27-alpine
â”‚   â”‚   â”œâ”€â”€ nginx.conf                   â† SPA routing + SSE proxy + asset caching
â”‚   â”‚   â””â”€â”€ Dockerfile.dockerignore
â”‚   â””â”€â”€ db/
â”‚       â””â”€â”€ Dockerfile                   â† postgres:15-alpine + seed scripts
â”‚
â”œâ”€â”€ db/
â”‚   â””â”€â”€ postgress/
â”‚       â”œâ”€â”€ 00_run_all.sql               â† master bootstrap script
â”‚       â”œâ”€â”€ 01_schema.sql                â† DDL: tables, indexes, triggers
â”‚       â”œâ”€â”€ 02_insert_departments.sql
â”‚       â”œâ”€â”€ 03_insert_employees.sql
â”‚       â”œâ”€â”€ 04_insert_employee_info.sql
â”‚       â”œâ”€â”€ 05_insert_suppliers.sql
â”‚       â”œâ”€â”€ 06_insert_products.sql
â”‚       â”œâ”€â”€ 07_insert_customers.sql
â”‚       â”œâ”€â”€ 08_insert_orders.sql
â”‚       â””â”€â”€ 09_insert_order_items.sql
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py                          â† FastAPI app factory + CORS + uvicorn entry point
â”‚   â”œâ”€â”€ requirements.txt                 â† pip dependencies
â”‚   â”œâ”€â”€ .env.example                     â† environment variable template
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ config/
â”‚       â”‚   â””â”€â”€ settings.py              â† Pydantic BaseSettings
â”‚       â”œâ”€â”€ db/
â”‚       â”‚   â”œâ”€â”€ adapters/
â”‚       â”‚   â”‚   â”œâ”€â”€ base.py               â† DatabaseAdapter ABC (interface)
â”‚       â”‚   â”‚   â”œâ”€â”€ postgres.py           â† PostgreSQL implementation
â”‚       â”‚   â”‚   â”œâ”€â”€ mysql.py              â† MySQL implementation
â”‚       â”‚   â”‚   â”œâ”€â”€ sqlite.py             â† SQLite implementation
â”‚       â”‚   â”‚   â””â”€â”€ factory.py            â† get_adapter() factory (reads DB_TYPE)
â”‚       â”œâ”€â”€ semantic/
â”‚       â”‚   â”œâ”€â”€ models.py                 â† SemanticColumn, SemanticTable models
â”‚       â”‚   â”œâ”€â”€ registry.py               â† SemanticRegistry + default seed data
â”‚       â”‚   â””â”€â”€ layer.py                  â† SemanticLayer (merges schema + semantics)
â”‚       â”œâ”€â”€ cache/
â”‚       â”‚   â””â”€â”€ redis_client.py          â† result cache + session history
â”‚       â”œâ”€â”€ agent/
â”‚       â”‚   â”œâ”€â”€ events.py                â† AgentEvent Pydantic models + EventType enum
â”‚       â”‚   â”œâ”€â”€ codeact_tool.py          â† CodeAct SQL Tool (yields AgentEvent stream)
â”‚       â”‚   â””â”€â”€ deep_agent.py            â† DeepAgent orchestrator (LLM + tool loop)
â”‚       â””â”€â”€ api/
â”‚           â”œâ”€â”€ schemas.py               â† ChatRequest / ChatInitResponse
â”‚           â””â”€â”€ routes/
â”‚               â”œâ”€â”€ chat.py              â† POST /chat + GET /chat/stream/{id}
â”‚               â”œâ”€â”€ health.py             â† GET /health (db adapter + redis check)
â”‚               â””â”€â”€ schema.py             â† GET /schema, GET /schema/{table}
â”‚
â””â”€â”€ ui/
    â”œâ”€â”€ index.html
    â”œâ”€â”€ package.json                     â† vite + react + tailwind + react-syntax-highlighter
    â”œâ”€â”€ vite.config.ts                   â† proxy /api â†’ localhost:8000
    â””â”€â”€ src/
        â”œâ”€â”€ main.tsx                     â† ReactDOM.createRoot
        â”œâ”€â”€ App.tsx                      â† root layout (header + ChatWindow + ChatInput)
        â”œâ”€â”€ index.css                    â† Tailwind directives
        â”œâ”€â”€ types/
        â”‚   â””â”€â”€ agent.ts                 â† AgentEvent + Message TypeScript types
        â”œâ”€â”€ api/
        â”‚   â””â”€â”€ chatApi.ts               â† initiateChat() + openEventStream()
        â”œâ”€â”€ hooks/
        â”‚   â””â”€â”€ useChat.ts               â† useChat() hook (state + SSE lifecycle)
        â””â”€â”€ components/
            â””â”€â”€ chat/
                â”œâ”€â”€ ChatWindow.tsx       â† scrollable message list
                â”œâ”€â”€ ChatInput.tsx        â† textarea + send button (Enter to send)
                â”œâ”€â”€ AssistantMessage.tsx â† renders all AgentEvent types
                â”œâ”€â”€ ThinkingIndicator.tsxâ† animated bounce dots
                â”œâ”€â”€ SqlBlock.tsx         â† Prism syntax highlighted SQL block
                â””â”€â”€ ResultTable.tsx      â† scrollable table with column headers
```

---

## ğŸ”’ Security Requirements

- Only `SELECT` statements permitted â€” block all DDL/DML in `QueryExecutor`
- Parameterized queries only â€” no string interpolation into SQL
- Session history scoped strictly to `session_id`
- CORS restricted to configured origins
- Environment variables for all secrets (never hardcode)

---

## âš™ï¸ Environment Variables

```env
# Application
APP_ENV=development

# Database type â€” postgresql | mysql | sqlite
DB_TYPE=postgresql
APP_HOST=0.0.0.0
APP_PORT=8000
CORS_ORIGINS=http://localhost:3000

# PostgreSQL
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=chatdb
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_POOL_SIZE=10
POSTGRES_MAX_OVERFLOW=20

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_TTL_SECONDS=3600

# LLM
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o
LLM_API_KEY=your_api_key_here
LLM_MAX_TOKENS=4096
LLM_TEMPERATURE=0.0

# DeepAgent
DEEPAGENT_MAX_ITERATIONS=10
DEEPAGENT_TIMEOUT_SECONDS=120
```

---

## ğŸš€ Run Instructions

### Option A â€” Docker (recommended)

```bash
cd deploy
cp .env.docker .env          # then set LLM_API_KEY=sk-...
docker compose up --build    # builds all 4 services

# Access:
#   UI  â†’ http://localhost:3000
#   API â†’ http://localhost:8000/docs  (Swagger)

# Rebuild a single service after code change:
docker compose up --build api
```

### Option B â€” Local (manual)

```bash
# API
cd api
python -m venv .venv
.venv\Scripts\activate          # Windows
# source .venv/bin/activate    # macOS / Linux
pip install -r requirements.txt
cp .env.example .env
python main.py                  # â†’ http://localhost:8000
                                # â†’ http://localhost:8000/docs (Swagger)

# UI
cd ui
npm install
npm run dev                     # â†’ http://localhost:3000

# Health check
curl http://localhost:8000/api/health
# Expected: { "api": "ok", "postgres": "ok", "redis": "ok" }
```

---

## ğŸ’¡ Extension Prompts

Use these follow-up prompts to extend the project:

| Goal | Prompt to use |
|---|---|
| Add Docker support | âœ… Done â€” see `deploy/` folder. Run: `cd deploy && cp .env.docker .env && docker compose up --build` |
| Add authentication | "Based on this PROMPT.md, add JWT authentication to the FastAPI API" |
| Add CSV export | "Based on this PROMPT.md, add a Download CSV button to ResultTable" |
| Add tests | "Based on this PROMPT.md, create pytest tests for the CodeAct tool and query executor" |
| Seed more tables | "Based on this PROMPT.md, add a `projects` and `timesheets` table to the DB scripts and semantic registry" |
| Add MySQL scripts | "Based on this PROMPT.md, create equivalent MySQL-compatible versions of the db/postgress/ scripts" |
| Add chart UI | "Based on this PROMPT.md, add a bar/line chart component that renders when the result set has numeric columns" |
| Add schema browser | "Based on this PROMPT.md, add a sidebar component to the UI showing all PostgreSQL tables and columns" |
| Multi-database support | "Based on this PROMPT.md, extend the architecture to support both PostgreSQL and MySQL" |
